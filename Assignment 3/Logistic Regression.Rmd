---
title: "Lecture 16 - Logistic Regression in R"
author: "Eugene Brusilovskiy"
date: "`r Sys.Date()`"
output: rmdformats::readthedown
---

## Setting Everything Up

We install a number of packages that we need in order to run logistic regression in R and specify the directory where our data are stored.

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/Jingyi's lenovo/Desktop/Penn/Fall 2023/MUSA 5000/Assignment 3")
options(scipen=999)  
```

```{r warning=FALSE, message=FALSE, cache=FALSE}
#install.packages("aod")
#install.packages("ggplot2")
#install.packages("rms")
#install.packages("gmodels")
#install.packages("nnet")
#install.packages("DAAG")
#install.packages("xtable")

library(aod)
library(ggplot2)
library(rms)
library(gmodels)
library(nnet)
library(DAAG)
library(ROCR)
library(xtable)
```

## Looking at the Data Set

Our (fictitious) data set has 300 zip codes. The relevant variables are described below:
-- Dependent Variable: ` Hospital`, where 0 means there's no hospital in the zip code and 1 means there is a hospital in the zip code 
-- Predictor: ` Population`, which is the number of people who live in the zip code
-- Predictor: ` NearbyHospital`, which is a binary indicator of whether there's a hospital in a nearby zip code (1=yes, 0=no). 
-- Predictor: ` Urban`, which is an indicator of whether the zip code is urban (1=yes, 0=no)


```{r warning=FALSE, message=FALSE, cache=FALSE}
mydata <- read.csv("Logistic Regression Data.csv")
head(mydata)
```

## Tabulation of the Dependent Variable Drinking_D
```{r warning=FALSE, message=FALSE, cache=FALSE}
DRINKING_D.tab <- table(mydata$DRINKING_D)
```

```{r}
table(mydata$DRINKING_D)
```


```{r}
prop.table(DRINKING_D.tab)
```



We see that there are 153 (51%) zip codes which have a hospital, and 147 (49%) zip codes which don't have a hospital. That is,  the probability of there being a hospital in the zip code can be calculated using the formula

$$Probability(Hospital) = \frac{Number \; of \; Zip \; Codes \; with \; a \; Hospital}{Total \; Number \; of \; Zip \; Codes} = \frac{153}{300} = .51. $$

Similarly, the odds of there being a hospital in a zip code can be calculated using the formula

$$Odds(Hospital) = \frac{Number \; of \; Zip \; Codes \; with \; a \; Hospital}{Number \; of \; Zip \; Codes \; without \; a \; Hospital} = \frac{153}{147} = 1.04. $$

##Cross-tabulations

```{r}
CrossTable(mydata$FATAL_OR_M, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE,
prop.chisq=FALSE, chisq=TRUE)
```
```{r}
CrossTable(mydata$OVERTURNED, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE,
prop.chisq=FALSE, chisq=TRUE)
```

```{r}
CrossTable(mydata$CELL_PHONE, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE,
prop.chisq=FALSE, chisq=TRUE)
```

```{r}
CrossTable(mydata$SPEEDING, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE,
prop.chisq=FALSE, chisq=TRUE)
```

```{r}
CrossTable(mydata$AGGRESSIVE, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE,
prop.chisq=FALSE, chisq=TRUE)
```

```{r}
CrossTable(mydata$DRIVER1617, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE,
prop.chisq=FALSE, chisq=TRUE)
```

```{r}
CrossTable(mydata$DRIVER65PLUS, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE,
prop.chisq=FALSE, chisq=TRUE)
```

## Means and standard deviations of two continuous predictors
```{r}
tapply(mydata$PCTBACHMOR, mydata$DRINKING_D, mean)
tapply(mydata$MEDHHINC, mydata$DRINKING_D, mean)
tapply(mydata$PCTBACHMOR, mydata$DRINKING_D, sd)
tapply(mydata$MEDHHINC, mydata$DRINKING_D, sd)
```

```{r}
t.test(mydata$PCTBACHMOR~mydata$DRINKING_D)
t.test(mydata$MEDHHINC~mydata$DRINKING_D)
```

## Pearson correlations
```{r}
predictors <- mydata[, c("PCTBACHMOR", "MEDHHINC", "FATAL_OR_M", "OVERTURNED", "CELL_PHONE", "SPEEDING", "AGGRESSIVE", "DRIVER1617", "DRIVER65PLUS")]
cor(predictors)
```

```{r}
library(kableExtra)

# Extracting the relevant predictors
predictors <- mydata[, c("PCTBACHMOR", "MEDHHINC", "FATAL_OR_M", "OVERTURNED", "CELL_PHONE", "SPEEDING", "AGGRESSIVE", "DRIVER1617", "DRIVER65PLUS")]

# Calculating the correlation matrix
cor_matrix <- cor(predictors)

# Creating a kable
kable(cor_matrix, align = "c") %>%
  kable_styling(full_width = FALSE)

```

## Multiple Logistic Regression

First, as an aside, if we had categorical predictors, we would need to use the ` factor` command to treat ` NearbyHospital` and ` Urban` as categorical variables. This isn't really necessary for binary variables, but needed for variables which have more than 2 categories. That is, for a categorical variable with _k_ categories, we would create _k_ dummies and include _k_-1 of them in the regression, as we discussed earlier in the semester.

```{r warning=FALSE, message=FALSE, cache=FALSE}
mydata$COLLISION_ <- factor(mydata$COLLISION_)
summary(mydata)
```

Now, let's run the multiple logistic regression:

```{r warning=FALSE, message=FALSE, cache=FALSE}
options(scipen=999)
mylogit <- glm(DRINKING_D ~ FATAL_OR_M + OVERTURNED + CELL_PHONE + SPEEDING + AGGRESSIVE + DRIVER1617 + DRIVER65PLUS + PCTBACHMOR + MEDHHINC, data = mydata, family = "binomial")
logitoutput <- summary(mylogit)
logitcoeffs <- logitoutput$coefficients
logitcoeffs[, "Pr(>|z|)"] <- round(logitcoeffs[, "Pr(>|z|)"], digits = 4)
#Merging beta coefficients, odds ratios and 95% confidence intervals
or_ci <- exp(cbind(OR = coef(mylogit), confint(mylogit)))
finallogitoutput <- cbind(logitcoeffs, or_ci)
finallogitoutput
```

Let's quickly interpret the results. Again, when we look at the p-values (column ` Pr(>|z|)`, only population is a significant predictor of our dependent variable, but for the sake of the example, let's pretend that all 3 predictors are significant:
-- First of all, the intercept $\beta_0$ = -7.522(Estimate), and the associated odds ratio = e^$\beta_0$^ = e^-7.522^ = .000541. This means that the odds of there being a hospital in a zip code where all 3 predictors are 0 (i.e., ` Population` = 0, ` Urban` = 0, meaning it's a non-urban zip code, and ` NearbyHospital` = 0, meaning that there's no hospital in a nearby zip code) are .000541.
-- $\beta_1$, the coefficient of the first predictor, ` Population`, is .0013654, and the associated odds ratio, e^$\beta_1$^ = 1.0014. This means that when urbanicity and the presence of a hospital in a nearby zip code are held constant, the odds of there being a hospital go up by a factor of 1.0014 as the population of the zip code goes up by 1 person. Similarly, if the population were to go up by, say, 500 people, the odds of there being a hospital in the zip code would go up by a factor of e^500$\beta_1$^ = 1.979.
-- $\beta_2$, the coefficient of the second predictor, ` NearbyHospital`, is .56, and the associated odds ratio is 1.75. This means that, holding other predictors constant, as ` NearbyHospital` goes up by 1 unit (i.e., goes from 0 to 1 in this case), the odds of there being a hospital in the zip code go up by a factor of 1.75.
-- The interpretation of $\beta_3$, which is the coefficient of ` Urban`, as well as the associated odds ratio, is left as an exercise for the student.



## Sensitivity, Specificity and Misclassification Rates
One way to assess how well our logistic regression performs is by examining the sensitivity (% of zip codes that actually have hospitals and have high predicted probabilities of having a hospital), specificity (% of zip codes that actually don't have hospitals and have low predicted probabilities of having a hospital), and the misclassification rate. To do this, we first need to get the predicted values from the model. These predicted values (y-hats) are the predicted probabilities of there being a hospital in each zip code.

```{r warning=FALSE, message=FALSE, cache=FALSE}
fit <- mylogit$fitted       #Getting the y-hats (i.e., predicted values)
hist(fit)       #Histogram of fitted values
```

When we look at the histogram of these predicted probabilities, we might want to define a high probability of there being a hospital in a zip code at .5 or higher, and a low probability of there being a hospital in a zip code at less than .5. Although .5 is a somewhat arbitrary guess for a cut-off, let's generate a dummy variable ` fit.binary` that sets the predicted values of y, ` fit`, to 1 if it's .5 or greater and to 0 otherwise.

```{r warning=FALSE, message=FALSE, cache=FALSE}
fit.binary = (fit>=0.5)
```

Now, let's do a cross-tabulation between the actual values of our dependent variable, ` Hospital`, and ` fit.binary`.

```{r warning=FALSE, message=FALSE, cache=FALSE}
CrossTable(fit.binary, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE, prop.chisq=FALSE)
```


```{r warning=FALSE, message=FALSE, cache=FALSE}
fit.binary = (fit>=0.2)
CrossTable(fit.binary, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE, prop.chisq=FALSE)
```

```{r warning=FALSE, message=FALSE, cache=FALSE}
fit.binary = (fit>=0.15)
CrossTable(fit.binary, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE, prop.chisq=FALSE)
```

```{r warning=FALSE, message=FALSE, cache=FALSE}
fit.binary = (fit>=0.1)
CrossTable(fit.binary, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE, prop.chisq=FALSE)
```

```{r warning=FALSE, message=FALSE, cache=FALSE}
fit.binary = (fit>=0.09)
CrossTable(fit.binary, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE, prop.chisq=FALSE)
```

```{r warning=FALSE, message=FALSE, cache=FALSE}
fit.binary = (fit>=0.08)
CrossTable(fit.binary, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE, prop.chisq=FALSE)
```

```{r warning=FALSE, message=FALSE, cache=FALSE}
fit.binary = (fit>=0.07)
CrossTable(fit.binary, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE, prop.chisq=FALSE)
```

```{r warning=FALSE, message=FALSE, cache=FALSE}
fit.binary = (fit>=0.05)
CrossTable(fit.binary, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE, prop.chisq=FALSE)
```

```{r warning=FALSE, message=FALSE, cache=FALSE}
fit.binary = (fit>=0.03)
CrossTable(fit.binary, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE, prop.chisq=FALSE)
```

```{r warning=FALSE, message=FALSE, cache=FALSE}
fit.binary = (fit>=0.02)
CrossTable(fit.binary, mydata$DRINKING_D, prop.r=FALSE, prop.t=FALSE, prop.chisq=FALSE)
```

## ROC Curve
Because we don't want to manually try out multiple probability cut-offs, it makes sense for us to generate the ROC package. For more info on the ` ROCR` package used here, see: https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/

First, let's create ` a`, which is a matrix combining the vectors containing the actual values of the dependent variable (` mydata$Hospital`) and the predicted probabilities, stored as ` fit`. 


```{r warning=FALSE, message=FALSE, cache=FALSE}
a <- cbind(mydata$DRINKING_D, fit)
head(a)
```

To summarize, we see that matrix ` a` has 2 columns. The first one is ` mydata$Hospital`, which are actual values of the depenent variable (i.e., labels), and the second one is ` fit`, which are predicted, or fitted values of y (i.e., predictions).

Let's make the names of the variables easy to understand, and call the two columns above ` labels` and ` predictions`, respsectively. We will then convert the matrix ` a` to a data frame called ` roc`.

```{r warning=FALSE, message=FALSE, cache=FALSE}
colnames(a) <- c("labels","predictions")
head(a)
roc <- as.data.frame(a)
```

Now, let's convert the data frame ` roc` to a prediction object, which is necessary for the generating the ROC plot with the ` ROCR` package. We do this using the ` prediction` command below. The order of the columns should be as below -- first the predictions, and then the actual values of the dependent variable.

```{r warning=FALSE, message=FALSE, cache=FALSE}
pred <- prediction(roc$predictions, roc$labels)
```

Now, let's plot the ROC curve, which takes the ` pred` object above as the input. On the y-axis, we have the True Positive Rate (` tpr` in the code below), which is another term for sensitivity. On the x-axis, we have the False Positive Rate (` fpr` in the code below), which is calculated as 1 - specificity. We also use the ` abline` command to plot the 45 degree line.

```{r warning=FALSE, message=FALSE, cache=FALSE}
roc.perf = performance(pred, measure = "tpr", x.measure="fpr")
plot(roc.perf)
abline(a=0,b=1)
```

In addition, if we want to weigh specificity and sensitivity equally, we can calculate the optimal probability cut-off. There are a couple ways to do so. One way is called the Youden Index, which identifies the cut-off probability that corresponds to the maximum possible sum of sensitivity and specificity. 

Another approach, calculated using the code below, is the cut-off value for which the ROC curve has the minimum distance from the upper left corner of the graph, where both specificity = 1 and sensitivity = 1. Because we are minimizing the distance from the upper left corner of the graph, where y = Sensitivity = True Positive Rate = ` tpr` = 1 and x = 1 - Specificity = False Positive Rate = ` fpr` = 0, the formula ` d = (x - 0)^2 + (y-1)^2` is used in the code below. We see that here, the cut-off that minimizes the distance from the upper left corner of the ROC curve is .336, and it corresponds to a sensitivity of .889 and a specificty of .864.

```{r warning=FALSE, message=FALSE, cache=FALSE}
opt.cut = function(perf, pred){
  cut.ind = mapply(FUN=function(x, y, p){
    d = (x - 0)^2 + (y-1)^2
    ind = which(d == min(d))
    c(sensitivity = y[[ind]], specificity = 1-x[[ind]], 
      cutoff = p[[ind]])
  }, perf@x.values, perf@y.values, pred@cutoffs)
}

print(opt.cut(roc.perf, pred))
```


Finally, we can also calculate the area under the curve, which is a measure of how well the model predicts 1 responses as 1's and 0 responses as 0's. Accuracy is measured by the area under the ROC curve. An area of 1 represents a perfect test (prediction); an area of .5 represents a worthless test (prediction). A rough guide for interpreting area under ROC Curves is below:

.90-1 = excellent (A)

.80-.90 = good    (B)

.70-.80 = fair    (C)

.60-.70 = poor    (D)

.50-.60 = fail    (F)

These might be somewhat conservative estimates, and there will be statisticians who will say that area > .7 is just fine. In our case, the area under the curve is .93, which is excellent.


```{r warning=FALSE, message=FALSE, cache=FALSE}
auc.perf = performance(pred, measure ="auc")
auc.perf@y.values
```

## Logistic Regression without PCTBACHMOR and MEDHHINC
```{r warning=FALSE, message=FALSE, cache=FALSE}
options(scipen=999)
mylogit2 <- glm(DRINKING_D ~ FATAL_OR_M + OVERTURNED + CELL_PHONE + SPEEDING + AGGRESSIVE + DRIVER1617 + DRIVER65PLUS, data = mydata, family = "binomial")
logitoutput2 <- summary(mylogit2)
logitcoeffs2 <- logitoutput2$coefficients
logitcoeffs2[, "Pr(>|z|)"] <- round(logitcoeffs2[, "Pr(>|z|)"], digits = 4)
#Merging beta coefficients, odds ratios and 95% confidence intervals
or_ci2 <- exp(cbind(OR = coef(mylogit2), confint(mylogit2)))
finallogitoutput2 <- cbind(logitcoeffs2, or_ci2)
finallogitoutput2
```

```{r}
AIC(mylogit, mylogit2)
```






